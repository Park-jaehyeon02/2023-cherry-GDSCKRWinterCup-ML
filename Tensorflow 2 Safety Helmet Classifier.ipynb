{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a35aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "from os import path\n",
    "import glob, matplotlib.pyplot as plt, matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a037d3f9",
   "metadata": {},
   "source": [
    "ann_path = './dataset/annotations/'\n",
    "img_path = './dataset/images'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path_annotations = []\n",
    "for i in Path(ann_path).glob('*.xml'):\n",
    "    path_annotations.append(i)\n",
    "path_annotations = sorted(path_annotations) #contains path to 5000 annots\n",
    "\n",
    "path_images = []\n",
    "for i in Path(img_path).glob('*.png'):\n",
    "    path_images.append(i)\n",
    "path_images = sorted(path_images) #contains path to 5000 images\n",
    "\n",
    "# making dirs to segregate train & val images & annotations & also to save best trained model\n",
    "import os\n",
    "\n",
    "# Creating directories to put train & val data\n",
    "os.makedirs('./train/helmet',exist_ok = True)\n",
    "os.makedirs('./train/head', exist_ok = True)\n",
    "os.makedirs('./val/helmet', exist_ok = True)\n",
    "os.makedirs('./val/head', exist_ok = True)\n",
    "os.makedirs('./savedmodel', exist_ok = True)\n",
    "\n",
    "helmetL = []\n",
    "headL = []\n",
    "\n",
    "for i in tqdm(range(len(path_annotations))):\n",
    "    flag_helmet = False\n",
    "    xtree = et.parse(path_annotations[i])\n",
    "    \n",
    "    for e in xtree.findall('object'):\n",
    "        name = e.find('name').text\n",
    "        if name=='helmet':\n",
    "            flag_helmet = True\n",
    "            break\n",
    "            \n",
    "    if flag_helmet:\n",
    "        helmetL.append(path_images[i].parts[-1])\n",
    "    else:\n",
    "        headL.append(path_images[i].parts[-1])\n",
    "        \n",
    "train_headL = headL[:300]\n",
    "val_headL = headL[300:]\n",
    "\n",
    "train_helmetL = helmetL[:3000]\n",
    "val_helmetL = helmetL[3000:]\n",
    "\n",
    "for i, path_img in tqdm(enumerate(train_helmetL)):\n",
    "    shutil.copy('./dataset/images/'+path_img, './train/helmet/' + path_img)\n",
    "    \n",
    "for i, path_img in tqdm(enumerate(val_helmetL)):\n",
    "    shutil.copy('./dataset/images/'+path_img, './val/helmet/' + path_img)\n",
    "    \n",
    "for i, path_img in tqdm(enumerate(train_headL)):\n",
    "    shutil.copy('./dataset/images/'+path_img, './train/head/' + path_img)\n",
    "    \n",
    "for i, path_img in tqdm(enumerate(val_headL)):\n",
    "    shutil.copy('./dataset/images/'+path_img, './val/head/' + path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc3b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3300 files belonging to 2 classes.\n",
      "Found 1700 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "train_dir = \"./train\"\n",
    "val_dir = \"./val\"\n",
    "\n",
    "\n",
    "train_data = image_dataset_from_directory(train_dir,label_mode = \"binary\",\n",
    "                                          image_size = (224,224),batch_size = 32,\n",
    "                                         shuffle = True,seed = 42)\n",
    "val_data = image_dataset_from_directory(val_dir,label_mode = \"binary\",\n",
    "                                          image_size = (224,224),batch_size = 32,\n",
    "                                         shuffle = False,seed = 42)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fab25c09",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "class_names = train_data.class_names\n",
    "\n",
    "for images, labels in val_data.take(1):\n",
    "    for i in range(32):\n",
    "        ax = plt.subplot(6, 6, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[0].numpy()))\n",
    "        #plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "# Class :  0-> head , 1 -> helmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc4b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.get_logger().setLevel('ERROR') # Suppress TensorFlow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69940b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 6,\n",
    "                                             min_delta = 0.0001)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\",factor = 0.2,\n",
    "                                                patience = 4,min_lr = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3115ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.EfficientNetB7(include_top = False)\n",
    "model.trainable = False\n",
    "# My GPU Memmory is short ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492fca1",
   "metadata": {},
   "source": [
    "<h1> Modeling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7ea969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = tf.keras.Sequential([\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.RandomFlip(\"horizontal\")\n",
    "],name = \"data_augmentation_layer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960ba776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation_layer (Se  (None, 224, 224, 3)      0         \n",
      " quential)                                                       \n",
      "                                                                 \n",
      " efficientnetb7 (Functional)  (None, None, None, 2560)  64097687 \n",
      "                                                                 \n",
      " pooling_layer (GlobalAverag  (None, 2560)             0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                81952     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,179,672\n",
      "Trainable params: 81,985\n",
      "Non-trainable params: 64,097,687\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape = (224,224,3),name = \"input_layer\")\n",
    "x = data_aug(inputs)\n",
    "x = model(x)\n",
    "x = layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n",
    "\n",
    "x = layers.Dense(32,activation = \"relu\",kernel_initializer = tf.keras.initializers.he_normal())(x)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = layers.Activation(\"sigmoid\",dtype = tf.float32)(x)\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed2ded8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a38998de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y = np.concatenate([y for x, y in train_data], axis=0)\n",
    "weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                            classes  = np.unique(np.ravel(y)),\n",
    "                                            y = np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "473497d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bac05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0: weights[0], 1:weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "055517cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5.5, 1: 0.55}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b134148",
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorB = tf.keras.callbacks.TensorBoard('./board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8772895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "104/104 [==============================] - 109s 908ms/step - loss: 0.3971 - accuracy: 0.7958 - val_loss: 0.2607 - val_accuracy: 0.9012 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "104/104 [==============================] - 82s 790ms/step - loss: 0.2851 - accuracy: 0.8655 - val_loss: 0.2320 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "104/104 [==============================] - 81s 775ms/step - loss: 0.2784 - accuracy: 0.8733 - val_loss: 0.3046 - val_accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "104/104 [==============================] - 81s 782ms/step - loss: 0.2305 - accuracy: 0.8897 - val_loss: 0.2452 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "104/104 [==============================] - 77s 743ms/step - loss: 0.2137 - accuracy: 0.8891 - val_loss: 0.1943 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "104/104 [==============================] - 79s 758ms/step - loss: 0.2109 - accuracy: 0.8955 - val_loss: 0.1924 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "104/104 [==============================] - 75s 721ms/step - loss: 0.2057 - accuracy: 0.8952 - val_loss: 0.2022 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "104/104 [==============================] - 77s 737ms/step - loss: 0.1834 - accuracy: 0.9079 - val_loss: 0.1612 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "104/104 [==============================] - 76s 734ms/step - loss: 0.1890 - accuracy: 0.9058 - val_loss: 0.1678 - val_accuracy: 0.9276 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "104/104 [==============================] - 75s 721ms/step - loss: 0.1792 - accuracy: 0.9082 - val_loss: 0.1329 - val_accuracy: 0.9482 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "104/104 [==============================] - 74s 707ms/step - loss: 0.1806 - accuracy: 0.9094 - val_loss: 0.1391 - val_accuracy: 0.9459 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "104/104 [==============================] - 73s 702ms/step - loss: 0.1779 - accuracy: 0.9082 - val_loss: 0.1519 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "104/104 [==============================] - 74s 712ms/step - loss: 0.1553 - accuracy: 0.9185 - val_loss: 0.1795 - val_accuracy: 0.9294 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "104/104 [==============================] - 71s 680ms/step - loss: 0.1552 - accuracy: 0.9233 - val_loss: 0.1871 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "104/104 [==============================] - 70s 675ms/step - loss: 0.1526 - accuracy: 0.9079 - val_loss: 0.1610 - val_accuracy: 0.9376 - lr: 2.0000e-04\n",
      "Epoch 16/20\n",
      "104/104 [==============================] - 71s 687ms/step - loss: 0.1345 - accuracy: 0.9282 - val_loss: 0.1467 - val_accuracy: 0.9406 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(train_data,epochs =20 , validation_data = val_data, \n",
    "                      callbacks = [early_stop,reduce_lr, TensorB], \n",
    "                      class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c158e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\admin\\anaconda3\\envs\\tens_lab\\lib\\site-packages (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a78eaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as pilimg\n",
    "\n",
    "im = pilimg.open( 'test.jpg' )\n",
    " \n",
    "# Display image\n",
    "im = im.resize((224,224))\n",
    "im.show()\n",
    "# Fetch image pixel data to numpy array\n",
    "pix = np.array(im).reshape(1,224,224,3)\n",
    "\n",
    "print(pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cb84dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99988997]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "820fcc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as pilimg\n",
    "\n",
    "im = pilimg.open( 'test2.jpg' )\n",
    " \n",
    "# Display image\n",
    "im = im.resize((224,224))\n",
    "im.show()\n",
    "# Fetch image pixel data to numpy array\n",
    "pix = np.array(im).reshape(1,224,224,3)\n",
    "\n",
    "print(pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "265607f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01809156]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2640f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as pilimg\n",
    "\n",
    "im = pilimg.open( 'test3.jpg' )\n",
    " \n",
    "# Display image\n",
    "im = im.resize((224,224))\n",
    "im.show()\n",
    "# Fetch image pixel data to numpy array\n",
    "pix = np.array(im).reshape(1,224,224,3)\n",
    "\n",
    "print(pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d81c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8446484]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e717444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 273). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msavedmodel/my_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tens_lab\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tens_lab\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tens_lab\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "model.save('savedmodel/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281debf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
